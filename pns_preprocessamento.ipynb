{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccca6b1",
   "metadata": {},
   "source": [
    "# üß† Divis√£o da Base, Tratamento de Outliers e Balanceamento (SMOTE)\n",
    "Este notebook realiza o pr√©-processamento dos dados da base **PNS 2019**, incluindo:\n",
    "- Carregamento da base final pr√©-balanceamento\n",
    "- Defini√ß√£o da vari√°vel alvo e features\n",
    "- Divis√£o em treino e teste\n",
    "- Tratamento de outliers (Capping nos percentis 1% e 99%)\n",
    "- Codifica√ß√£o (Ordinal, One-Hot e Escalonamento)\n",
    "- Aplica√ß√£o do SMOTE para balanceamento do conjunto de treino\n",
    "- Salvamento dos conjuntos processados em arquivos `.npy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293d921f",
   "metadata": {},
   "source": [
    "## üì¶ 1. Importa√ß√£o das Bibliotecas Necess√°rias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62bc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, OrdinalEncoder \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"10\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8feaa3",
   "metadata": {},
   "source": [
    "## üìÇ 2. Carregar a Base de Dados Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe82da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'pns_final_pre_balanceamento.csv' carregado com sucesso.\n",
      "Shape da base (desbalanceada): (1288, 31)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arquivo_para_ler = 'pns_final_pre_balanceamento.csv'\n",
    "try:\n",
    "    df = pd.read_csv(arquivo_para_ler, sep=';', decimal=',')\n",
    "    print(f\"Arquivo '{arquivo_para_ler}' carregado com sucesso.\")\n",
    "    print(f\"Shape da base (desbalanceada): {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"üõë Erro: Arquivo '{arquivo_para_ler}' n√£o foi encontrado.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92d7c21",
   "metadata": {},
   "source": [
    "## üéØ 3. Definir a Vari√°vel Alvo (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3328092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TARGET_COLUMN = 'DIABETES' \n",
    "\n",
    "if TARGET_COLUMN not in df.columns:\n",
    "    print(f\"üõë Erro: A coluna alvo '{TARGET_COLUMN}' n√£o foi encontrada no DataFrame.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251b120",
   "metadata": {},
   "source": [
    "## üß© 4. Definir Listas de Features (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7e97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colunas_numericas = [\n",
    "    \"IDADE\", \"RENDA_TOTAL\", \"Peso_Final\", \"Altura_Final_cm\", \"IMC\"\n",
    "]\n",
    "\n",
    "colunas_ordinais = [\n",
    "    \"FEIJAO\", \"VERDURA_LEGUME\", \"FREQ_VERDURA_LEGUME\", \"CARNE_VERMELHA\", \n",
    "    \"FRANGO_GALINHA\", \"PEIXE\", \"SUCO_INDUSTRIALIZADO\", \"SUCO_NATURAL\", \n",
    "    \"FRUTA_SEMANA\", \"FREQ_FRUTA_DIA\", \"REFRIGERANTE_SEMANA\", \"DOCES_SEMANA\", \n",
    "    \"SUBSTITUIR_REFEICAO_DOCE_SEMANA\", \"CONSUMO_SAL\", \"NIVEL_CONSUMO_ALCOOL\", \n",
    "    \"NIVEL_ATIVIDADE_FISICA\", \"FAIXA_RENDA_SM\"\n",
    "]\n",
    "\n",
    "colunas_nominais = [\n",
    "    \"SEXO\", \"PLANO_SAUDE\", \"GRAVIDEZ\", \"TIPO_SUCO_INDUSTIALIZADO\", \n",
    "    \"TIPO_REFRIGERANTE\", \"LEITE_SEMANA\", \"TIPO_LEITE\", \"COMA_DIABETICO\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6553fb1a",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è 5. Dividir a Base em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0064f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Distribui√ß√£o das classes (Antes do SMOTE) ---\n",
      "Treino (y_train):\n",
      " DIABETES\n",
      "2    0.732519\n",
      "1    0.267481\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Teste (y_test):\n",
      " DIABETES\n",
      "2    0.73385\n",
      "1    0.26615\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n--- Distribui√ß√£o das classes (Antes do SMOTE) ---\")\n",
    "print(\"Treino (y_train):\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\nTeste (y_test):\\n\", y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e996651",
   "metadata": {},
   "source": [
    "## üìä 6. Tratamento de Outliers (Capping nos Percentis 1% e 99%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abe367a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aplicando Capping (Tratamento de Outliers) nos Percentis 1% e 99%...\n",
      "  [IDADE]: Limites (de Treino) -> Inf=35.00, Sup=78.00\n",
      "  [RENDA_TOTAL]: Limites (de Treino) -> Inf=100.00, Sup=13300.00\n",
      "  [Peso_Final]: Limites (de Treino) -> Inf=45.20, Sup=119.40\n",
      "  [Altura_Final_cm]: Limites (de Treino) -> Inf=145.00, Sup=188.00\n",
      "  [IMC]: Limites (de Treino) -> Inf=18.44, Sup=41.80\n",
      "Capping conclu√≠do.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nAplicando Capping (Tratamento de Outliers) nos Percentis 1% e 99%...\")\n",
    "\n",
    "for col in colunas_numericas:\n",
    "    limite_inferior = X_train[col].quantile(0.01)\n",
    "    limite_superior = X_train[col].quantile(0.99)\n",
    "    \n",
    "    print(f\"  [{col}]: Limites (de Treino) -> Inf={limite_inferior:.2f}, Sup={limite_superior:.2f}\")\n",
    "    \n",
    "    X_train[col] = X_train[col].clip(lower=limite_inferior, upper=limite_superior)\n",
    "    X_test[col] = X_test[col].clip(lower=limite_inferior, upper=limite_superior)\n",
    "\n",
    "print(\"Capping conclu√≠do.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e128337",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 7. Cria√ß√£o dos Pipelines de Pr√©-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11db50f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aplicando One-Hot, Ordinal Encoding e Scaling...\n",
      "Pr√©-processamento conclu√≠do.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, colunas_numericas),\n",
    "        ('nom', nominal_transformer, colunas_nominais),\n",
    "        ('ord', ordinal_transformer, colunas_ordinais) \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "print(\"\\nAplicando One-Hot, Ordinal Encoding e Scaling...\")\n",
    "\n",
    "X_train_final = preprocessor.fit_transform(X_train)\n",
    "X_test_final = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Pr√©-processamento conclu√≠do.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a94ebf",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è 8. Aplicar o SMOTE (Balanceamento do Conjunto de Treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1e4833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aplicando SMOTE apenas nos dados de TREINO...\n",
      "\n",
      "--- Distribui√ß√£o das classes (Depois do SMOTE) ---\n",
      "Treino (y_train_smote):\n",
      " DIABETES\n",
      "2    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- SHAPES FINAIS ---\n",
      "X_train_smote (p/ Modelo): (1320, 50)\n",
      "y_train_smote (p/ Modelo): (1320,)\n",
      "X_test_final (p/ Avalia√ß√£o): (387, 50)\n",
      "y_test (p/ Avalia√ß√£o): (387,)\n",
      "\n",
      "‚úÖ Processo conclu√≠do!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nAplicando SMOTE apenas nos dados de TREINO...\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_final, y_train)\n",
    "\n",
    "print(\"\\n--- Distribui√ß√£o das classes (Depois do SMOTE) ---\")\n",
    "print(\"Treino (y_train_smote):\\n\", pd.Series(y_train_smote).value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n--- SHAPES FINAIS ---\")\n",
    "print(f\"X_train_smote (p/ Modelo): {X_train_smote.shape}\")\n",
    "print(f\"y_train_smote (p/ Modelo): {y_train_smote.shape}\")\n",
    "print(f\"X_test_final (p/ Avalia√ß√£o): {X_test_final.shape}\")\n",
    "print(f\"y_test (p/ Avalia√ß√£o): {y_test.shape}\")\n",
    "\n",
    "print(\"\\n‚úÖ Processo conclu√≠do!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58665c68",
   "metadata": {},
   "source": [
    "## üíæ 9. Salvar os Conjuntos Processados em Arquivos `.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bf4dcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Conjuntos de treino (balanceado) e teste (desbalanceado) salvos como arquivos .npy.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.save('X_train_smote.npy', X_train_smote)\n",
    "np.save('y_train_smote.npy', y_train_smote)\n",
    "np.save('X_test_final.npy', X_test_final)\n",
    "np.save('y_test.npy', y_test)\n",
    "\n",
    "print(\"\\nüíæ Conjuntos de treino (balanceado) e teste (desbalanceado) salvos como arquivos .npy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0958e-c003-43ea-ba7e-c27f35f19b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
